import os
import json
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict
from queue import Queue
from threading import Lock

import dotenv
import argparse
from tqdm import tqdm

import langchain_core.exceptions
from langchain_openai import ChatOpenAI
from langchain.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from structure import Structure

if os.path.exists('.env'):
    dotenv.load_dotenv()
template = open("template.txt", "r").read()
system = open("system.txt", "r").read()

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser()
    parser.add_argument("--data", type=str, required=True, help="jsonline data file")
    parser.add_argument("--max_workers", type=int, default=1, help="Maximum number of parallel workers")
    return parser.parse_args()

def process_single_item(chain, item: Dict, language: str) -> Dict:
    """å¤„ç†å•ä¸ªæ•°æ®é¡¹"""
    try:
        response: Structure = chain.invoke({
            "language": language,
            "content": item['summary']
        })
        item['AI'] = response.model_dump()
    except langchain_core.exceptions.OutputParserException as e:
        # å°è¯•ä»é”™è¯¯ä¿¡æ¯ä¸­æå– JSON å­—ç¬¦ä¸²å¹¶ä¿®å¤
        error_msg = str(e)
        if "Function Structure arguments:" in error_msg:
            try:
                # æå– JSON å­—ç¬¦ä¸²
                json_str = error_msg.split("Function Structure arguments:", 1)[1].strip().split('are not valid JSON')[0].strip()
                # é¢„å¤„ç† LaTeX æ•°å­¦ç¬¦å· - ä½¿ç”¨å››ä¸ªåæ–œæ æ¥ç¡®ä¿æ­£ç¡®è½¬ä¹‰
                json_str = json_str.replace('\\', '\\\\')
                # å°è¯•è§£æä¿®å¤åçš„ JSON
                fixed_data = json.loads(json_str)
                item['AI'] = fixed_data
                return item
            except Exception as json_e:
                print(f"Failed to fix JSON for {item['id']}: {json_e} {json_str}", file=sys.stderr)
        
        # å¦‚æœä¿®å¤å¤±è´¥ï¼Œè¿”å›é”™è¯¯çŠ¶æ€
        item['AI'] = {
            "tldr": "Error",
            "motivation": "Error",
            "method": "Error",
            "result": "Error",
            "conclusion": "Error"
        }
    return item

def process_all_items(data: List[Dict], model_name: str, language: str, max_workers: int) -> List[Dict]:
    """å¹¶è¡Œå¤„ç†æ‰€æœ‰æ•°æ®é¡¹"""
    deepseek_base_url = os.environ.get("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1") # å¯ä»¥ä»ç¯å¢ƒå˜é‡è·å–
    llm = ChatOpenAI(
        model=model_name,
        base_url=deepseek_base_url  # ğŸ‘ˆ å…³é”®ä¿®æ”¹ï¼šæŒ‡å®š DeepSeek çš„ API åœ°å€
    ).with_structured_output(Structure, method="function_calling")
    print('Connect to:', model_name, file=sys.stderr)
    
    prompt_template = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(system),
        HumanMessagePromptTemplate.from_template(template=template)
    ])

    chain = prompt_template | llm
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    processed_data = [None] * len(data)  # é¢„åˆ†é…ç»“æœåˆ—è¡¨
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_idx = {
            executor.submit(process_single_item, chain, item, language): idx
            for idx, item in enumerate(data)
        }
        
        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
        for future in tqdm(
            as_completed(future_to_idx),
            total=len(data),
            desc="Processing items"
        ):
            idx = future_to_idx[future]
            try:
                result = future.result()
                processed_data[idx] = result
            except Exception as e:
                print(f"Item at index {idx} generated an exception: {e}", file=sys.stderr)
                failed_item = data[idx]
                failed_item['AI'] = {   # ğŸ‘ˆ ç»™å¤±è´¥çš„æ¡ç›®è¡¥ä¸ªå ä½
                    "tldr": "AIå¢å¼ºå¤±è´¥",
                    "motivation": "",
                    "method": "",
                    "result": "",
                    "conclusion": ""
                }
                processed_data[idx] = failed_item

    
    return processed_data

def main():
    args = parse_args()
    model_name = os.environ.get("MODEL_NAME", 'deepseek-chat')
    language = os.environ.get("LANGUAGE", 'Chinese')

    # æ£€æŸ¥å¹¶åˆ é™¤ç›®æ ‡æ–‡ä»¶
    target_file = args.data.replace('.jsonl', f'_AI_enhanced_{language}.jsonl')
    if os.path.exists(target_file):
        os.remove(target_file)
        print(f'Removed existing file: {target_file}', file=sys.stderr)

    # è¯»å–æ•°æ®
    data = []
    with open(args.data, "r") as f:
        for line in f:
            data.append(json.loads(line))

    # å»é‡
    seen_ids = set()
    unique_data = []
    for item in data:
        if item['id'] not in seen_ids:
            seen_ids.add(item['id'])
            unique_data.append(item)

    data = unique_data
    print('Open:', args.data, file=sys.stderr)
    
    # å¹¶è¡Œå¤„ç†æ‰€æœ‰æ•°æ®
    processed_data = process_all_items(
        data,
        model_name,
        language,
        args.max_workers
    )
    
    # ä¿å­˜ç»“æœ
    with open(target_file, "w") as f:
        for item in processed_data:
            f.write(json.dumps(item) + "\n")

if __name__ == "__main__":
    main()
